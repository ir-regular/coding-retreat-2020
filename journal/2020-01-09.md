# Developer journal, 9 January 2020

Planned: C refresher.

Book: "Modern C"

## Accountability

Changed Qbserve setup to alert after 25m, 50m, ... 2h 30m spent learning per day,
and update Beeminder with 30 minutes every time one of the alerts pops up.

## Actually reviewing C and not going mad

Challenge 1.2 (quicksort) done today. For some reason went quicker than yesterday ;)

General learnings: _everything_ new causes cognitive load,
and so does making decisions, so you feel very stupid at the beginning.
"Oh I used to know that algorithm!" Yes, but you don't know how to do stuff
in the language you're using, you don't have an IDE set up, the compiler/debugger
setup is new, and by the time you're done with the basics it's 20 in the evening
and you're tired.

So all I'm saying is, if you the reader do this, don't beat yourself up.

### Syntax, cont'd

In C, it's `else if` (as opposed to `elseif`, or `elif`, that you might have encountered
elsewhere. I know.)

> case values must be integer constant expressions

sadface

> Division by zero is forbidden.

thumbs up

`&&` and `||` short circuit.
C also has a ternary operator. Yay, 21st century has arrived. 

> [comma operator] is a trap for beginners: A[i, j] is not a two-dimensional index for matrix A, but results in A[j]

(Who writes code like this?)

> Most operators don’t sequence their operands.

OOO this is interesting. Only `&&`, `||`, `?:`, and `,` have a defined order of evaluation.

> Because union is a keyword, we use capital letters to name the operations here.

so, `union` is a keyword but `Union` is cool for userland code. AARGH.

### Types

The type `size_t` represents values in the range [0, SIZE_MAX].
The value of `SIZE_MAX` is quite large. Depending on the platform, it is one of

- 216 − 1 = 65535
- 232 − 1 = 4294967295
- 264 − 1 = 18446744073709551615

The first value is a minimal requirement; nowadays, such a small value would only occur on some embedded platforms. The other two values are much more commonly used today: the second is still found on some PCs and laptops, and the large majority of newer platforms have the third.

size_t overflows and wraps around: `SIZE_MAX + 1 == 0` or `0 - 1 == SIZE_MAX`

- `stdint.h`: `SIZE_MAX`, `PTRDIFF_MIN`, `PTRDIFF_MAX`
- `float.h`: `DBL_MIN`, `DBL_MAX`
- `limits.h`: `INT_MIN`, `INT_MAX`, `UINT_MAX`, `ULONG_MAX`, `ULLONG_MAX`, `CHAR_MIN`, `CHAR_MAX`, `UCHAR_MAX`
- `stdbool.h`: `true`, `false`

Nowadays, platforms usually provide `uint8_t`, `uint16_t`, `uint32_t`, and `uint64_t` unsigned types
and `int8_t`, `int16_t`, `int32_t`, and `int64_t` signed types. Their presence and bounds can be tested
with the macros `UINT8_MAX`, ..., `UINT64_MAX` for unsigned types and `INT8_MIN`, `INT8_MAX`, ...,
`INT64_MIN` and `INT64_MAX`, respectively - all in `stdint.h`

> For an optimization to be valid, it is only important that a C compiler produces an executable
> that reproduces the observable states.

(So it could do math calculations at compile time, and leave variables initialised to the resulting
value for example.)

> binary representation of the type: model to represent values of a given type on a given platform.
> C library headers provide the necessary information through named values (such as SIZE_MAX), operators, and function calls.
> (abstract representation)

> object representation: how values are stored in the memory of a computer or on a disk or other persistent storage device

> overflow of an unsigned type is not a problem, and the result of the condensed operation will always be
> consistent with the two separate ones. For other types, such as signed integer types (signed) and
> floating-point types (double), an overflow may raise an exception and terminate the program

Mind blown. Unsigned overflows without consequences because why the hell not. Whereas with the other ones,
an overflow _may_ raise an exception.

> the system of basic types is a bit complicated

is the author British?

This is making me appreciate untyped languages again.

> There is a first level of specification that is done entirely with keywords of the language,
> such as signed, int, and double. This first level is mainly organized according to C internals.
> 
> On top of that is a second level of specification that comes through header files, and we have
> already seen examples: size_t and bool. This second level is organized by type semantics,
> specifying what properties a particular type brings to the programmer.

There is a type `long long`. Next C demo I write is going to have a `long long cat;` declaration.

> Takeaway 1.5.2.3 Use size_t for sizes, cardinalities, or ordinal numbers.
> Takeaway 1.5.2.4 Use unsigned for small quantities that can’t be negative.
> Takeaway 1.5.2.5 Use signed for small quantities that bear a sign.
> Takeaway 1.5.2.6 Use ptrdiff_t for large differences that bear a sign.
> Takeaway 1.5.2.7 Use double for floating-point calculations.
> Takeaway 1.5.2.8 Use double complex for complex calculations.

> clock_t values present the platform’s model of processor clock cycles,
> so the unit of time is usually much less than a second; CLOCKS_PER_SEC
> can be used to convert such values to seconds

`time_t` calendar time in seconds since epoch

> Consecutive string literals are concatenated.

okay

> Decimal integer constants are signed.

interesting

> The effective value of a decimal floating-point constant may be different from its literal value.

good reminder

`__STDC_NO_COMPLEX__` is what you check to see if complex numbers are available. I do not foresee this being a problem
I will encounter in my near future.

### Initialization

`double A[] = { 7.8, };` - nice, you don't have to specify array length if you initialize it immediately.

Initialize everything unless it needs to be optimized. (Initialization costs... but then initialization to 0 also does)

> If you don’t know how to initialize a variable of type T, the default initializer T a = {0} will almost always do.

### Constants

Name your constants! Distinguish different uses of the same value!

You can declare an enum! Enumeration constants are of `signed int` type.

**NOTE the technique of adding a "number of elements in this enum" as the last element of enum.**

```c
enum corvid { magpie , raven , jay , chough , corvid_num , };

enum { p0 = 1, p1 = 2*p0, p2 = 2*p1, p3 = 2*p2, };
```

integer constant expression (ICE) provides a compile-time integer value.

- value must be determinable at compile time
- no function call allowed
- no evaluation of an object must participate as an operand to the value

(Annoyingly, _object_ includes scalar variables.) 

So, principally, an ICE may consist of any operations with integer literals,
enumeration constants, _Alignof and offsetof subexpressions, and eventually
some sizeof subexpressions.

### Aside: what does const keyword do?

`const` is a type qualifier (other: `volatile`, `restrict`)

`const int` means the same thing as `int const`, but don't do the former, qualifier should always appear to the right.

> A value of type T const cannot be assigned to, except when initialized.

```c
typedef int const int_const;                      // An unassignable int
typedef int_const * const int_const_ptr_const;    // An unassignable pointer to an unassignable int

// so if you merge the lines, you'd get:
// typedef int const * const int_const_ptr_const;
```

> Note in particular that int can be soundly converted to int const.
> Unassignable is not the same as immutable.

### Macros

A macro accomplishes textual replacement of the program code, because you cannot declare
constants of other types than `signed int`. (aargh.)

There must be no ; at the end of the macro definition.

`#define M_PI 3.14159265358979323846`

Defining a macro with a compound literal:

```c
enum corvid { magpie , raven , jay , chough , corvid_num , };

# define CORVID_NAME /**/ \
(char const*const[corvid_num]){ \
  [chough] = "chough", \
  [raven] = "raven", \
  [magpie] = "magpie", \
  [jay] = "jay", \
}
```

### Binary representation, bit operators

As you would expect. "precision": how many bits there are.
Least significant bit: the rightmost 1.
Most significant bit: the leftmost 1.

Operators: `&`, `|`, `^` and `~` (also `&=`, `|=`, and `^=`)

Aliases in `iso646.h`: `bitor`, `bitand`, `xor`, `or_eq`, `and_eq`, `xor_eq`, and `compl` 

Good use: flags (define macros with successive powers of 2). Then, a single number can represent a set,
and bits 1/0 presence or absence of an element within the set.

Left shift: `<<` is the same as "multiply by two" (add a zero to the right). Second operand
must be less than precision

Right shift: `>>` is the same as "divide by two".

Example use:

```c

enum corvid { magpie , raven , jay , chough , corvid_num , };

#define FLOCK_MAGPIE (1U << magpie)
#define FLOCK_RAVEN (1U << raven)
#define FLOCK_JAY (1U << jay)
#define FLOCK_CHOUGH (1U << chough)

#define FLOCK_EMPTY 0U
#define FLOCK_FULL ((1U << corvid_num)-1)
```

### How are signed values represented?

C allows three different sign representations:

- Sign and magnitude (historical; positive and negative 0)
- One's complement (historical; positive and negative 0)
- Two's complement

> upper half of unsigned values (those with a high-order bit of 1) is interpreted as being negative

For unsigned types, `-A` can be computed as `~A + 1`

```c
bool is_negative(unsigned a) {
    unsigned const int_max = UINT_MAX /2;
    return a > int_max;
}

bool is_signed_less(unsigned a, unsigned b) {
    if (is_negative(b) && !is_negative(a)) return false;
    else return a < b;
}
```

Negation may overflow for signed arithmetic.

> In twos’ complement representation, INT_MIN < -INT_MAX
> Or, stated otherwise, in twos’ complement representation, the positive value -INT_MIN
> is out of bounds since the value of the operation is larger than INT_MAX

### Derived data types

- arrays (aggregate data type; all elements of the same type)
- structures (aggregate data type; elements may be of different types)
- pointers (refer to an object in memory)
- unions (overlay items of different base types in the same memory location)

`typedef` creates a new name for an existing type.

### Arrays

The length of an array can be computed with the sizeof operator: `(sizeof A) / (sizeof A[0])`

Fixed length arrays: length determined by an ICE.

Variable length arrays: length determined by an expression that is not an ICE.

VLA were introduced in C99. Can't have initializers, only exist within functions.

Multidimensional arrays: Both C and D are "M objects of array type `double[N]`":

```c
double C[M][N];
double (D[M])[N];
```

### Wat (a collection of things I don't understand from all other sections)

> case labels must not jump beyond a variable definition

`alignof` ???

`ptrdiff_t` ???

Why initialization with `{0}` works for structs and non-variable-length arrays:

> if we omit the designation (the .membername for struct or [n] for arrays) initialization is just done
> in declaration order: that is, the 0 in the default initializer designates the very first member that
> is declared, and all other members are then initialized by default to 0 as well.
> annoyingly, some compiler implementers don’t know about this special rule

`char const * const` I think this is a string? An unassignable pointer to an unassignable character

> If introduced today, the type of string literals would certainly be char const[],
> an array of const-qualified characters. Unfortunately, the const keyword was introduced
> to the C language much later than string literals, and therefore it remained as it is
> for backward compatibility.

For signed integers...

> The shift operations then become really messy. The semantics of what such an operation is for a negative value is not clear

...so unclear or undefined?
